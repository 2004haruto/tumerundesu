"""
å®Œå…¨ãªå®Ÿé¨“ãƒ•ãƒ­ãƒ¼ã®å®Ÿè¡Œä¾‹
AIã‚¼ãƒŸç™ºè¡¨ç”¨ãƒ‡ãƒ¢ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import logging
from pathlib import Path

from detector import BentoBoxDetector
from evaluator import ModelEvaluator
from plot_results import ResultVisualizer
from experiment_metadata import ExperimentMetadata

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def run_complete_experiment():
    """å®Œå…¨ãªå®Ÿé¨“ãƒ•ãƒ­ãƒ¼ã‚’å®Ÿè¡Œ"""
    
    print("\n" + "="*70)
    print("ğŸ± å¼å½“ç®±æ¤œå‡ºAI - ç ”ç©¶å®Ÿé¨“ãƒ‡ãƒ¢ï¼ˆAIã‚¼ãƒŸç”¨ï¼‰")
    print("="*70 + "\n")
    
    # ============================================================
    # STEP 1: å®Ÿé¨“ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä½œæˆ
    # ============================================================
    print("ğŸ“‹ STEP 1: å®Ÿé¨“ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä½œæˆä¸­...")
    metadata_mgr = ExperimentMetadata(output_dir="./outputs")
    
    metadata_path = metadata_mgr.generate_metadata(
        experiment_name="å¼å½“ç®±æ¤œå‡º3ãƒ¢ãƒ¼ãƒ‰æ¯”è¼ƒå®Ÿé¨“ v1.0",
        model_name="YOLOv3 + OpenCV",
        confidence_threshold=0.5,
        nms_threshold=0.4,
        remarks="AIã‚¼ãƒŸç ”ç©¶ç™ºè¡¨ç”¨ãƒ»åˆå›å®Ÿé¨“"
    )
    
    print(f"âœ… ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†: {metadata_path}\n")
    
    # ============================================================
    # STEP 2: æ¤œå‡ºå™¨åˆæœŸåŒ–
    # ============================================================
    print("ğŸ”§ STEP 2: æ¤œå‡ºå™¨åˆæœŸåŒ–ä¸­...")
    detector = BentoBoxDetector(
        yolo_weights_path=None,  # å®Ÿéš›ã®ãƒ‘ã‚¹ã«å¤‰æ›´
        yolo_config_path=None,   # å®Ÿéš›ã®ãƒ‘ã‚¹ã«å¤‰æ›´
        confidence_threshold=0.5,
        nms_threshold=0.4,
        output_dir="./outputs"
    )
    print("âœ… æ¤œå‡ºå™¨åˆæœŸåŒ–å®Œäº†\n")
    
    # ============================================================
    # STEP 3: è©•ä¾¡å®Ÿè¡Œï¼ˆ3ãƒ¢ãƒ¼ãƒ‰æ¯”è¼ƒï¼‰
    # ============================================================
    print("ğŸ” STEP 3: 3ãƒ¢ãƒ¼ãƒ‰æ¯”è¼ƒè©•ä¾¡é–‹å§‹...")
    print("   - OpenCVå˜ä½“ãƒ¢ãƒ¼ãƒ‰")
    print("   - YOLOå˜ä½“ãƒ¢ãƒ¼ãƒ‰")
    print("   - Hybridï¼ˆä½µç”¨ï¼‰ãƒ¢ãƒ¼ãƒ‰\n")
    
    evaluator = ModelEvaluator(detector, output_dir="./outputs")
    
    # ãƒ†ã‚¹ãƒˆç”»åƒãƒ•ã‚©ãƒ«ãƒ€ãƒ‘ã‚¹ï¼ˆåˆ‡ã‚Šå–ã‚Šæ¸ˆã¿ç”»åƒã‚’ä½¿ç”¨ï¼‰
    test_folder = "./test_images_cropped"
    
    # ãƒ†ã‚¹ãƒˆãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã—ãªã„å ´åˆã®å‡¦ç†
    if not Path(test_folder).exists():
        print(f"âš ï¸  è­¦å‘Š: ãƒ†ã‚¹ãƒˆãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {test_folder}")
        print(f"   ãƒ‡ãƒ¢ç”¨ç”»åƒã‚’é…ç½®ã—ã¦ã‹ã‚‰å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚\n")
        return
    
    # ãƒ¢ãƒƒã‚¯æ­£è§£ãƒ‡ãƒ¼ã‚¿ï¼ˆå®Ÿéš›ã®å®Ÿé¨“ã§ã¯å®Ÿæ¸¬å€¤ã‚’ä½¿ç”¨ï¼‰
    ground_truths = {
        "test1.jpg": [100, 100, 200, 150],
        "test2.jpg": [120, 80, 220, 160],
        "test3.jpg": [110, 90, 210, 155],
    }
    
    try:
        summary = evaluator.evaluate_folder(test_folder, ground_truths)
        print("âœ… è©•ä¾¡å®Œäº†\n")
    except Exception as e:
        logger.error(f"è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
        print(f"âš ï¸  è©•ä¾¡ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ãƒ†ã‚¹ãƒˆç”»åƒã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚\n")
        return
    
    # ============================================================
    # STEP 4: ã‚°ãƒ©ãƒ•ç”Ÿæˆ
    # ============================================================
    print("ğŸ“Š STEP 4: çµæœå¯è¦–åŒ–ï¼ˆã‚°ãƒ©ãƒ•ç”Ÿæˆï¼‰...")
    visualizer = ResultVisualizer(output_dir="./outputs/visualizations")
    
    metrics_csv = Path("./outputs/metrics.csv")
    if metrics_csv.exists():
        visualizer.plot_from_csv(str(metrics_csv))
        print("âœ… ã‚°ãƒ©ãƒ•ç”Ÿæˆå®Œäº†")
        print("   - accuracy_comparison.png")
        print("   - speed_comparison.png")
        print("   - success_rate_comparison.png")
        print("   - comprehensive_comparison.png\n")
    else:
        print("âš ï¸  ãƒ¡ãƒˆãƒªã‚¯ã‚¹CSVãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\n")
    
    # ============================================================
    # STEP 5: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ›´æ–°
    # ============================================================
    print("ğŸ“ STEP 5: å®Ÿé¨“çµæœã§ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ›´æ–°...")
    metadata_mgr.update_with_results(metadata_path, summary)
    print("âœ… ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ›´æ–°å®Œäº†\n")
    
    # ============================================================
    # STEP 6: ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    # ============================================================
    print("ğŸ“„ STEP 6: å®Ÿé¨“ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ...")
    report_path = metadata_mgr.generate_experiment_report(
        metadata_path,
        output_format='markdown'
    )
    print(f"âœ… ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: {report_path}\n")
    
    # ============================================================
    # å®Œäº†ã‚µãƒãƒªãƒ¼
    # ============================================================
    print("\n" + "="*70)
    print("ğŸ‰ å®Ÿé¨“å®Œäº†ï¼")
    print("="*70)
    print("\nğŸ“ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«:")
    print(f"   - ãƒ¡ãƒˆãƒªã‚¯ã‚¹: outputs/metrics.csv")
    print(f"   - ã‚µãƒãƒªãƒ¼: outputs/evaluation_summary.json")
    print(f"   - ãƒ­ã‚°: outputs/logs/")
    print(f"   - ã‚°ãƒ©ãƒ•: outputs/visualizations/")
    print(f"   - ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿: {metadata_path}")
    print(f"   - ãƒ¬ãƒãƒ¼ãƒˆ: {report_path}")
    print("\nğŸ’¡ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("   1. outputs/visualizations/ ã®ã‚°ãƒ©ãƒ•ã‚’ç¢ºèª")
    print("   2. outputs/metrics.csv ã§ãƒ¢ãƒ¼ãƒ‰é–“ã®æ•°å€¤æ¯”è¼ƒ")
    print("   3. experiment_report.md ã‚’ AIã‚¼ãƒŸç™ºè¡¨è³‡æ–™ã«æ´»ç”¨")
    print("\n" + "="*70 + "\n")


if __name__ == "__main__":
    run_complete_experiment()
